{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Potential Outcomes and RCTs (Python Implementation)\n",
    "\n",
    "This notebook implements analysis of potential outcomes and randomized controlled trials using Python.\n",
    "\n",
    "## Assignment Requirements:\n",
    "1. **Data Simulation (3 points)**: Simulate dataset with covariates, treatment, and outcome\n",
    "2. **Estimating Average Treatment Effect (3 points)**: Simple and controlled regression estimates\n",
    "3. **LASSO and Variable Selection (3 points)**: Use LASSO for covariate selection and ATE estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "print(\"üì¶ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Simulation (3 points)\n",
    "\n",
    "We simulate a dataset with n = 1000 individuals with:\n",
    "- Covariates X‚ÇÅ, X‚ÇÇ, X‚ÇÉ, X‚ÇÑ (continuous or binary)\n",
    "- Treatment assignment D ~ Bernoulli(0.5)\n",
    "- Outcome variable: Y = 2D + 0.5X‚ÇÅ - 0.3X‚ÇÇ + 0.2X‚ÇÉ + Œµ, where Œµ ~ N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "n = 1000\n",
    "\n",
    "# Generate covariates\n",
    "X1 = np.random.normal(2, 1, n)           # Continuous covariate\n",
    "X2 = np.random.normal(0, 1.5, n)        # Continuous covariate\n",
    "X3 = np.random.binomial(1, 0.3, n)      # Binary covariate\n",
    "X4 = np.random.binomial(1, 0.6, n)      # Binary covariate\n",
    "\n",
    "# Generate treatment assignment\n",
    "D = np.random.binomial(1, 0.5, n)       # Treatment ~ Bernoulli(0.5)\n",
    "\n",
    "# Generate error term\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "\n",
    "# Generate outcome variable: Y = 2D + 0.5X1 - 0.3X2 + 0.2X3 + Œµ\n",
    "Y = 2*D + 0.5*X1 - 0.3*X2 + 0.2*X3 + epsilon\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Y': Y,\n",
    "    'D': D,\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'X3': X3,\n",
    "    'X4': X4\n",
    "})\n",
    "\n",
    "print(\"üìä Dataset simulated successfully\")\n",
    "print(f\"Sample size: {len(data)}\")\n",
    "print(f\"Treatment group size: {sum(data['D'])}\")\n",
    "print(f\"Control group size: {sum(1 - data['D'])}\\n\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Check (1 point)\n",
    "\n",
    "We perform a balance check by comparing the means of X‚ÇÅ, X‚ÇÇ, X‚ÇÉ, X‚ÇÑ across treatment and control groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance check: compare means across treatment groups\n",
    "control_group = data[data['D'] == 0]\n",
    "treatment_group = data[data['D'] == 1]\n",
    "\n",
    "balance_results = []\n",
    "for var in ['X1', 'X2', 'X3', 'X4']:\n",
    "    control_mean = control_group[var].mean()\n",
    "    treatment_mean = treatment_group[var].mean()\n",
    "    difference = treatment_mean - control_mean\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(treatment_group[var], control_group[var])\n",
    "    \n",
    "    balance_results.append({\n",
    "        'Variable': var,\n",
    "        'Control_Mean': control_mean,\n",
    "        'Treatment_Mean': treatment_mean,\n",
    "        'Difference': difference,\n",
    "        'p_value': p_value\n",
    "    })\n",
    "\n",
    "balance_df = pd.DataFrame(balance_results)\n",
    "\n",
    "print(\"üîç Balance Check Results:\")\n",
    "print(balance_df.round(4))\n",
    "print(\"\\nüìà Balance is good if differences are small and p-values are > 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Estimating the Average Treatment Effect (3 points)\n",
    "\n",
    "We estimate the Average Treatment Effect (ATE) using two approaches:\n",
    "1. Simple regression: Y ~ D\n",
    "2. Controlled regression: Y ~ D + X‚ÇÅ + X‚ÇÇ + X‚ÇÉ + X‚ÇÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple regression: Y ~ D\n",
    "X_simple = sm.add_constant(data['D'])  # Add constant for intercept\n",
    "simple_model = sm.OLS(data['Y'], X_simple).fit()\n",
    "\n",
    "print(\"üìä Simple Regression Results (Y ~ D):\")\n",
    "print(simple_model.summary())\n",
    "\n",
    "# Extract ATE and standard error\n",
    "simple_ate = simple_model.params['D']\n",
    "simple_se = simple_model.bse['D']\n",
    "\n",
    "print(f\"\\nüéØ Simple ATE estimate: {simple_ate:.4f}\")\n",
    "print(f\"üìè Standard Error: {simple_se:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Controlled regression: Y ~ D + X1 + X2 + X3 + X4\n",
    "X_controlled = sm.add_constant(data[['D', 'X1', 'X2', 'X3', 'X4']])\n",
    "controlled_model = sm.OLS(data['Y'], X_controlled).fit()\n",
    "\n",
    "print(\"üìä Controlled Regression Results (Y ~ D + X1 + X2 + X3 + X4):\")\n",
    "print(controlled_model.summary())\n",
    "\n",
    "# Extract ATE and standard error\n",
    "controlled_ate = controlled_model.params['D']\n",
    "controlled_se = controlled_model.bse['D']\n",
    "\n",
    "print(f\"\\nüéØ Controlled ATE estimate: {controlled_ate:.4f}\")\n",
    "print(f\"üìè Standard Error: {controlled_se:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two estimates\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Simple (Y ~ D)', 'Controlled (Y ~ D + X1 + X2 + X3 + X4)'],\n",
    "    'ATE_Estimate': [simple_ate, controlled_ate],\n",
    "    'Standard_Error': [simple_se, controlled_se],\n",
    "    'R_Squared': [simple_model.rsquared, controlled_model.rsquared]\n",
    "})\n",
    "\n",
    "print(\"üìã Comparison of ATE Estimates:\")\n",
    "print(comparison.round(4))\n",
    "\n",
    "print(\"\\nüîç Analysis:\")\n",
    "print(f\"‚Ä¢ ATE change: {controlled_ate - simple_ate:.4f}\")\n",
    "print(f\"‚Ä¢ Standard error change: {controlled_se - simple_se:.4f}\")\n",
    "print(\"‚Ä¢ The true ATE is 2.0 (from our data generating process)\")\n",
    "print(\"‚Ä¢ Controlling for covariates should improve precision and reduce bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 LASSO and Variable Selection (3 points)\n",
    "\n",
    "We use LASSO to select covariates and then re-estimate the ATE with only the selected variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LASSO (excluding treatment D)\n",
    "X_matrix = data[['X1', 'X2', 'X3', 'X4']].values\n",
    "Y_vector = data['Y'].values\n",
    "\n",
    "# Standardize features for LASSO\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_matrix)\n",
    "\n",
    "# Fit LASSO model using cross-validation\n",
    "lasso_cv = LassoCV(cv=10, random_state=123, max_iter=10000)\n",
    "lasso_cv.fit(X_scaled, Y_vector)\n",
    "\n",
    "# Plot cross-validation results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(lasso_cv.alphas_, lasso_cv.mse_path_.mean(axis=1))\n",
    "plt.axvline(lasso_cv.alpha_, color='red', linestyle='--', label=f'Optimal Œ± = {lasso_cv.alpha_:.4f}')\n",
    "plt.xlabel('Alpha (Œª)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('LASSO Cross-Validation')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "# Plot coefficient path\n",
    "plt.subplot(1, 2, 2)\n",
    "alphas = np.logspace(-4, 1, 100)\n",
    "coefs = []\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_scaled, Y_vector)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "coefs = np.array(coefs)\n",
    "for i in range(4):\n",
    "    plt.plot(alphas, coefs[:, i], label=f'X{i+1}')\n",
    "plt.axvline(lasso_cv.alpha_, color='red', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Alpha (Œª)')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Coefficient Path')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üéØ Optimal alpha (Œª): {lasso_cv.alpha_:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients and selected variables\n",
    "lasso_coef = lasso_cv.coef_\n",
    "variable_names = ['X1', 'X2', 'X3', 'X4']\n",
    "selected_vars = [var for var, coef in zip(variable_names, lasso_coef) if abs(coef) > 1e-6]\n",
    "\n",
    "print(\"üìä LASSO Coefficients:\")\n",
    "for var, coef in zip(variable_names, lasso_coef):\n",
    "    print(f\"{var}: {coef:.6f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Variables selected by LASSO: {selected_vars}\")\n",
    "\n",
    "if len(selected_vars) == 0:\n",
    "    print(\"‚ö†Ô∏è  No variables selected by LASSO at optimal Œ±\")\n",
    "    print(\"This might indicate that the penalty is too strong or variables are not predictive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-estimate ATE with LASSO-selected covariates\n",
    "if len(selected_vars) > 0:\n",
    "    # Create design matrix with selected variables\n",
    "    X_lasso = sm.add_constant(data[['D'] + selected_vars])\n",
    "    lasso_model = sm.OLS(data['Y'], X_lasso).fit()\n",
    "    \n",
    "    print(f\"üìä LASSO-Selected Model Results (Y ~ D + {' + '.join(selected_vars)}):\")\n",
    "    print(lasso_model.summary())\n",
    "    \n",
    "    # Extract ATE and standard error\n",
    "    lasso_ate = lasso_model.params['D']\n",
    "    lasso_se = lasso_model.bse['D']\n",
    "    \n",
    "    print(f\"\\nüéØ LASSO ATE estimate: {lasso_ate:.4f}\")\n",
    "    print(f\"üìè Standard Error: {lasso_se:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No variables selected by LASSO - using simple model\")\n",
    "    lasso_ate = simple_ate\n",
    "    lasso_se = simple_se\n",
    "    selected_vars_str = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison of all three estimates\n",
    "selected_vars_str = ', '.join(selected_vars) if len(selected_vars) > 0 else \"None\"\n",
    "\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Model': ['Simple', 'Controlled', 'LASSO-Selected'],\n",
    "    'ATE_Estimate': [simple_ate, controlled_ate, lasso_ate],\n",
    "    'Standard_Error': [simple_se, controlled_se, lasso_se],\n",
    "    'Variables_Used': ['None', 'X1, X2, X3, X4', selected_vars_str]\n",
    "})\n",
    "\n",
    "print(\"üìã Final Comparison of All ATE Estimates:\")\n",
    "print(final_comparison.round(4))\n",
    "\n",
    "print(\"\\nüîç Discussion:\")\n",
    "print(\"‚Ä¢ True ATE: 2.0\")\n",
    "print(\"‚Ä¢ LASSO helps with variable selection in high-dimensional settings\")\n",
    "print(\"‚Ä¢ In this case, we know X4 has no true effect (coefficient = 0)\")\n",
    "print(\"‚Ä¢ LASSO should ideally select X1, X2, X3 and exclude X4\")\n",
    "print(\"‚Ä¢ Benefits of LASSO: reduces overfitting, improves interpretability\")\n",
    "print(\"‚Ä¢ LASSO may improve precision by removing irrelevant variables\")\n",
    "\n",
    "# Visualization of results\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = final_comparison['Model']\n",
    "estimates = final_comparison['ATE_Estimate']\n",
    "errors = final_comparison['Standard_Error']\n",
    "\n",
    "plt.errorbar(range(len(models)), estimates, yerr=errors, fmt='o', capsize=5)\n",
    "plt.axhline(y=2.0, color='red', linestyle='--', label='True ATE = 2.0')\n",
    "plt.xticks(range(len(models)), models, rotation=45)\n",
    "plt.ylabel('ATE Estimate')\n",
    "plt.title('Comparison of ATE Estimates with Confidence Intervals')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}